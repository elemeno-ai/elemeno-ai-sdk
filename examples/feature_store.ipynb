{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94a51891-b325-4f0f-bf31-385c0e032020",
   "metadata": {},
   "source": [
    "# Feature store example\n",
    "---\n",
    "\n",
    "The idea of this notebook is to give a example on how we manage:\n",
    "- Ingest data in a batch way\n",
    "- Retrieve data from the feature store for training and inference mode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa977ee9-e58e-4e2d-adbc-c529b1da24cd",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3212e840-b421-4fab-b333-c328115d6ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2308da-b3df-4cc2-aa8c-35fd989695d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from typing import List\n",
    "from datetime import datetime\n",
    "\n",
    "import feast\n",
    "import pandas as pd\n",
    "from elemeno_ai_sdk.ml.features.feature_store import FeatureStore\n",
    "from elemeno_ai_sdk.ml.features.feature_table import FeatureTable\n",
    "from elemeno_ai_sdk.ml.features.ingest.sink.ingestion_sink_builder import IngestionSinkType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5f8936-3a1b-455e-bd57-f3060960a68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"insert here your aws access key id\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"insert here your aws secret access key\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809b811e-19ad-41c8-863b-7e93b19b513d",
   "metadata": {},
   "source": [
    "### Dataframe to ingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d17da9e-1f1a-43f9-9aad-dd25a9a4f9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = \"./example_data/datasource.csv\"\n",
    "data = pd.read_csv(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df531f02-6f28-4a23-92dc-966ddcb3570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af052c90-f445-4295-bc5f-b28f13327ea8",
   "metadata": {},
   "source": [
    "### Creating feature store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47587ab1-67cb-4884-b686-395a015b58b5",
   "metadata": {},
   "source": [
    "Instantiate the Feature Store object, since we are working with a csv file we do not need to pass a `source_type` into the constructor, we just need to pass the `sink_type` which in our case will be `REDSHIFT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a87f3d-eb95-45ff-9c9f-a1dd2c194f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store = FeatureStore(\n",
    "    sink_type=IngestionSinkType.REDSHIFT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7fbf69-523f-4c1b-b013-67a2b669ade5",
   "metadata": {},
   "source": [
    "Now we create a Feature Table object. First I parse the id and feature columns to feast `Entity` and `Feature` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f11cd1-a25a-43cf-9de4-135af7e31cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(id_columns: List[str]) -> List[feast.Entity]:\n",
    "    return [feast.Entity(name=id_col) for id_col in id_columns] \n",
    "\n",
    "def get_features(feature_list: List[str]) -> List[feast.Feature]:\n",
    "    features = []\n",
    "    for feature in feature_list:\n",
    "        if feature == \"created_timestamp\" or feature == \"event_timestamp\":\n",
    "            dtype = feast.ValueType.BYTES\n",
    "        elif feature == \"target\":\n",
    "            dtype = feast.ValueType.INT32\n",
    "        else:\n",
    "            dtype = feast.ValueType.FLOAT\n",
    "        features.append(feast.Feature(name=feature, dtype=dtype))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0705218d-833c-4561-9af0-d960d2029dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_TABLE_NAME = \"one_blinc_ft\"\n",
    "FEATURES = [col for col in data.columns if col != \"id\"]\n",
    "IDS = [\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2e7de1-d147-463a-bb08-dd4b6bb7b0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_table = FeatureTable(\n",
    "    name=FEATURE_TABLE_NAME,\n",
    "    feature_store=feature_store,\n",
    "    entities=get_entities(id_columns=IDS),\n",
    "    features=get_features(feature_list=FEATURES),\n",
    "    online=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8abe70-ccbe-4fcb-aaac-18bce0317699",
   "metadata": {},
   "source": [
    "### Ingest features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4472778f-b358-416f-a476-09908b0840c5",
   "metadata": {},
   "source": [
    "To ingest features we call the `ingest` method and we need to pass the `feature_table` we just created and the `dataframe` we want to save. \n",
    "\n",
    "We can also pass two more additional params, `renames` which will rename the features and `all_columns` which will filtered the features from your data source before sending to the feature store, for the purpose of our example we will leave it as ***None***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94092087-a52e-4b92-819e-9af31c302530",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store.ingest(\n",
    "    feature_table=feature_table, \n",
    "    to_ingest=data, \n",
    "    renames=None, \n",
    "    all_columns=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c697b9-7459-415f-907f-9fdbe6ce7265",
   "metadata": {},
   "source": [
    "### Retrieve features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0e9033-3f97-4cc9-8cd3-60e858ca5cf7",
   "metadata": {},
   "source": [
    "- #### For training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6583ba6e-bc95-4f39-9345-3c0ee1fe4fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_data = feature_store.get_training_features(feature_table=feature_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6b7598-1c68-413a-9c56-f29b718aa32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d020d63-47e7-4fb2-8a92-bf4e1d231977",
   "metadata": {},
   "source": [
    "- #### For inference:\n",
    "  To retrieve features for model inference we need to do two things first:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50499af4-f4ee-4882-b79f-fa69b0bdb4df",
   "metadata": {},
   "source": [
    "1) Creating feature view;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e52763f-0a4f-4b3c-b558-2ba907cd22bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view = feature_table.get_view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcfbe04-7aae-4019-a309-86c171199fd2",
   "metadata": {},
   "source": [
    "\n",
    "2) Load features from offline store to online store using feast materialize incremental method;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd45ad13-f51d-4435-8e59-1a5faaf3ae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store.fs.materialize_incremental(\n",
    "    end_date=datetime.utcnow(), \n",
    "    feature_views=[feature_view.name]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58292e31-14a7-4d9a-99c5-0fcad860eba7",
   "metadata": {},
   "source": [
    "And now we can retrieve the features for inference as a pandas dataframe or as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c89c6f-202b-4326-a5a2-497765151fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTITIES = [0, 1, 2]\n",
    "ENTITY_NAME = \"id\"\n",
    "FEATURES = [\"sepal_length\", \"sepal_width\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc474cac-10da-4e9a-be42-f80b886df412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_features(feature_view_name: str, features: List[str]) -> List[str]:\n",
    "    return [f\"{feature_view_name}:{feature}\" for feature in features]\n",
    "\n",
    "def parse_entities(entity_name: str, entity_values: List[int]):\n",
    "    return [{entity_name: entity_value} for entity_value in entity_values]\n",
    "    \n",
    "def retrieve_features_for_inference(\n",
    "    feature_store: FeatureStore, \n",
    "    feature_view_name: str, \n",
    "    entity_name: str,\n",
    "    entities: List[int],\n",
    "    features: List[str],\n",
    "    as_df: bool = True\n",
    "):\n",
    "    inference_features = feature_store.get_online_features(\n",
    "        entities=parse_entities(entity_name=entity_name, entity_values=entities),\n",
    "        requested_features=parse_features(feature_view_name=feature_view_name, features=features)\n",
    "    )\n",
    "\n",
    "    return inference_features.to_df() if as_df else inference_features.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc88081e-77de-41f9-a060-30695e6c30bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = retrieve_features_for_inference(\n",
    "    feature_store=feature_store, \n",
    "    feature_view_name=feature_view.name, \n",
    "    entity_name=ENTITY_NAME,\n",
    "    entities=ENTITIES,\n",
    "    features=FEATURE_LIST,\n",
    "    as_df=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c79415-31f9-4ba7-a718-a6777bb9f193",
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c7b505-7ed5-45d0-bcdf-ff831ce6d454",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
